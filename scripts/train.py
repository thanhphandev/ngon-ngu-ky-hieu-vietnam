import os
import numpy as np
import argparse
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC # Support Vector Machine
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from datetime import datetime

def plot_confusion_matrix(y_true, y_pred, classes, save_path):
    """V·∫Ω v√† l∆∞u ma tr·∫≠n nh·∫ßm l·∫´n"""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix (Ma tr·∫≠n nh·∫ßm l·∫´n)')
    plt.ylabel('Nh√£n th·ª±c t·∫ø (True Label)')
    plt.xlabel('Nh√£n d·ª± ƒëo√°n (Predicted Label)')
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Confusion Matrix t·∫°i: {save_path}")
    plt.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser("Training model")

    parser.add_argument("--model_name", help="Name of the model",
                        type=str, default="model")
    parser.add_argument("--dir", help="Location of the model",
                        type=str, default="models")
    args = parser.parse_args()

    print("=" * 80)
    print(f"üß† B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN M√î H√åNH: {args.model_name}")
    print("=" * 80)

    start_time = datetime.now()
    X, y, mapping = [], [], dict()

    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c '{data_dir}'.")
        exit(1)

    pose_files = list(os.scandir(data_dir))
    
    # L·ªçc ch·ªâ l·∫•y file .npy
    pose_files = [f for f in pose_files if f.name.endswith('.npy')]

    if not pose_files:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu .npy n√†o trong '{data_dir}'.")
        exit(1)

    print(f"üìÇ T√¨m th·∫•y {len(pose_files)} file d·ªØ li·ªáu trong '{data_dir}'.")
    print("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu...")

    for current_class_index, pose_file in enumerate(pose_files):
        file_path = os.path.join(data_dir, pose_file.name)
        try:
            pose_data = np.load(file_path)
            # Ki·ªÉm tra d·ªØ li·ªáu r·ªóng
            if pose_data.size == 0:
                print(f"‚ö†Ô∏è C·∫£nh b√°o: File {pose_file.name} r·ªóng, b·ªè qua.")
                continue
                
            X.append(pose_data)
            y += [current_class_index] * pose_data.shape[0]
            mapping[current_class_index] = pose_file.name.split(".")[0]
            print(f"  + ƒê√£ t·∫£i l·ªõp '{mapping[current_class_index]}': {pose_data.shape[0]} m·∫´u")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc file {pose_file.name}: {e}")

    if not X:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hu·∫•n luy·ªán.")
        exit(1)

    X, y = np.vstack(X), np.array(y)
    print(f"‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng.")
    print(f"‚Üí T·ªïng s·ªë m·∫´u: {X.shape[0]}")
    print(f"‚Üí S·ªë l∆∞·ª£ng l·ªõp: {len(mapping)} ({list(mapping.values())})\n")

    print("üöÄ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh SVM...")
    # Chia t·∫≠p train/test t·ªâ l·ªá 80/20
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # C·∫•u h√¨nh SVM: probability=True ƒë·ªÉ c√≥ th·ªÉ t√≠nh ƒë·ªô tin c·∫≠y (confidence score) sau n√†y
    model = SVC(decision_function_shape='ovo', kernel='rbf', C=100.0, gamma='scale', probability=True)
    model.fit(X_train, y_train)

    # ƒê√°nh gi√°
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)

    print("\n" + "-" * 30)
    print("K·∫æT QU·∫¢ HU·∫§N LUY·ªÜN")
    print("-" * 30)
    print(f"Training samples: {X_train.shape[0]}")
    print(f"Testing samples:  {X_test.shape[0]}")
    print(f"Classes: {len(mapping)}")
    print(f"‚úÖ Train Accuracy: {train_accuracy * 100:.2f}%")
    print(f"‚úÖ Test Accuracy:  {test_accuracy * 100:.2f}%")

    # L∆∞u model
    os.makedirs(args.dir, exist_ok=True)
    model_path = os.path.join(args.dir, f"{args.model_name}.pkl")
    with open(model_path, "wb") as file:
        pickle.dump((model, mapping), file)

    # V·∫Ω Confusion Matrix
    try:
        class_names = [mapping[i] for i in sorted(mapping.keys())]
        cm_path = os.path.join(args.dir, f"{args.model_name}_confusion_matrix.png")
        plot_confusion_matrix(y_test, y_test_pred, class_names, cm_path)
        
        # In b√°o c√°o chi ti·∫øt d·∫°ng text
        print("\nChi ti·∫øt t·ª´ng l·ªõp (Classification Report):")
        print(classification_report(y_test, y_test_pred, target_names=class_names))
        
    except Exception as e:
        print(f"\n‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì (c√≥ th·ªÉ thi·∫øu th∆∞ vi·ªán matplotlib/seaborn): {e}")

    duration = (datetime.now() - start_time).seconds
    print(f"\nüíæ Model ƒë√£ l∆∞u t·∫°i: {model_path}")
    print(f"‚è±Ô∏è Ho√†n th√†nh trong {duration} gi√¢y.")
    print("=" * 80)
